{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haraldriisager/ML-Project/blob/weather-api/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!pip install openmeteo-requests\n",
        "!pip install requests-cache retry-requests numpy pandas\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "LWXG8x_1elMA",
        "outputId": "8d28caf0-45c1-4c72-ba81-ddaecb034816",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Collecting openmeteo-requests\n",
            "  Downloading openmeteo_requests-1.3.0-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting openmeteo-sdk>=1.4.0 (from openmeteo-requests)\n",
            "  Downloading openmeteo_sdk-1.18.0-py3-none-any.whl.metadata (934 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmeteo-requests) (2.32.3)\n",
            "Requirement already satisfied: flatbuffers>=24.0.0 in /usr/local/lib/python3.10/dist-packages (from openmeteo-sdk>=1.4.0->openmeteo-requests) (24.3.25)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (2024.8.30)\n",
            "Downloading openmeteo_requests-1.3.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading openmeteo_sdk-1.18.0-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: openmeteo-sdk, openmeteo-requests\n",
            "Successfully installed openmeteo-requests-1.3.0 openmeteo-sdk-1.18.0\n",
            "Collecting requests-cache\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting retry-requests\n",
            "  Downloading retry_requests-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (24.2.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache)\n",
            "  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (2.32.3)\n",
            "Collecting url-normalize>=1.4 (from requests-cache)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (2.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests-cache) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests-cache) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests-cache) (2024.8.30)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retry_requests-2.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: url-normalize, cattrs, retry-requests, requests-cache\n",
            "Successfully installed cattrs-24.1.2 requests-cache-1.2.1 retry-requests-2.0.0 url-normalize-1.4.3\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "import openmeteo_requests\n",
        "from openmeteo_sdk.Variable import Variable\n",
        "import requests_cache\n",
        "from requests_cache import CachedSession\n",
        "from retry_requests import retry\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ],
      "metadata": {
        "id": "hITlT10JOT9y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Flight Delay data set\n",
        "\n",
        "file_id = '14aF7ZORUZFGKoAG7IE9Cd6vjTLtU2ytz'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'data.csv', quiet=False)\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df.columns)\n",
        "print(df.shape[0])"
      ],
      "metadata": {
        "id": "xrsZyQIgLrt2",
        "outputId": "0b86b2a3-3b76-4ac6-93c9-6145d6a81f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=14aF7ZORUZFGKoAG7IE9Cd6vjTLtU2ytz\n",
            "From (redirected): https://drive.google.com/uc?id=14aF7ZORUZFGKoAG7IE9Cd6vjTLtU2ytz&confirm=t&uuid=b55ac6f0-eba5-4b6d-8454-cbcd6f4f578d\n",
            "To: /content/data.csv\n",
            "100%|██████████| 614M/614M [00:12<00:00, 48.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['FL_DATE', 'AIRLINE', 'AIRLINE_DOT', 'AIRLINE_CODE', 'DOT_CODE',\n",
            "       'FL_NUMBER', 'ORIGIN', 'ORIGIN_CITY', 'DEST', 'DEST_CITY',\n",
            "       'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF',\n",
            "       'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY',\n",
            "       'CANCELLED', 'CANCELLATION_CODE', 'DIVERTED', 'CRS_ELAPSED_TIME',\n",
            "       'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'DELAY_DUE_CARRIER',\n",
            "       'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS', 'DELAY_DUE_SECURITY',\n",
            "       'DELAY_DUE_LATE_AIRCRAFT'],\n",
            "      dtype='object')\n",
            "3000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Airport locations data set\n",
        "\n",
        "file_id = '1eK1b3XX3jl-9XtQrH-_924YjV3rlqUFB'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'airport_locations.csv', quiet=False)\n",
        "airport_locations = pd.read_csv('airport_locations.csv', delimiter=';')\n",
        "\n",
        "airport_locations = airport_locations[['Airport Code', 'Latitude', 'Longitude']].dropna()\n",
        "airport_locations = airport_locations.set_index('Airport Code').to_dict(orient='index')"
      ],
      "metadata": {
        "id": "N1vRDaQRSsSn",
        "outputId": "f47d8bcc-6999-4408-f7be-99684373b9d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eK1b3XX3jl-9XtQrH-_924YjV3rlqUFB\n",
            "To: /content/airport_locations.csv\n",
            "100%|██████████| 875k/875k [00:00<00:00, 100MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the origin and destination coordinates to the data set\n",
        "\n",
        "def get_airport_coordinates(airport_code):\n",
        "  if airport_code in airport_locations:\n",
        "    return airport_locations[airport_code]['Latitude'], airport_locations[airport_code]['Longitude']\n",
        "  return None, None\n",
        "\n",
        "df[\"ORIGIN_LAT\"], df[\"ORIGIN_LONG\"] = zip(*df[\"ORIGIN\"].apply(get_airport_coordinates))\n",
        "df[\"DEST_LAT\"], df[\"DEST_LONG\"] = zip(*df[\"DEST\"].apply(get_airport_coordinates))"
      ],
      "metadata": {
        "id": "lEAMiXh8Rzmq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows that have null coordinates\n",
        "\n",
        "missing_coordinates_rows = df[df[['ORIGIN_LAT', 'ORIGIN_LONG', 'DEST_LAT', 'DEST_LONG']].isna().any(axis=1)]\n",
        "\n",
        "missing_count = missing_coordinates_rows.shape[0]\n",
        "\n",
        "missing_origin = set(missing_coordinates_rows['ORIGIN'])\n",
        "missing_destination = set(missing_coordinates_rows['DEST'])\n",
        "missing_airports = missing_origin.union(missing_destination)\n",
        "\n",
        "print(\"Airport codes with missing coordinates:\", list(missing_airports))\n",
        "print(\"Number of rows with missing coordinates:\", missing_count)\n",
        "\n",
        "df = df.dropna(subset=['ORIGIN_LAT', 'ORIGIN_LONG', 'DEST_LAT', 'DEST_LONG'])\n",
        "\n",
        "print(\"Number of rows after removal:\", df.shape[0])\n",
        "\n",
        "df = df[:10000]\n",
        "\n",
        "print(\"Number of rows after removal:\", df.shape[0])"
      ],
      "metadata": {
        "id": "DeKREx0xz2Kx",
        "outputId": "72b53e3a-1789-4ac4-b91d-7e740f497423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Airport codes with missing coordinates: ['ICT', 'DFW', 'BKG', 'MSY', 'GRI', 'EUG', 'FSD', 'FCA', 'BOS', 'SBN', 'ECP', 'IND', 'SAN', 'XWA', 'FNT', 'TUL', 'XNA', 'SRQ', 'MEM', 'AZA', 'MLB', 'TXK', 'BLV', 'LGA', 'BLI', 'TVC', 'PIT', 'FLL', 'PIE', 'OMA', 'MDW', 'SMX', 'SGF', 'MKE', 'ATW', 'JAC', 'MSO', 'HPN', 'SGU', 'GRR', 'AMA', 'DAL', 'FWA', 'RAP', 'SFB', 'STC', 'SNA', 'MOT', 'GEG', 'BNA', 'JFK', 'MVY', 'VPS', 'CLT', 'MCI', 'DEN', 'PHL', 'PGD', 'BZN', 'PVU', 'PSC', 'RFD', 'LAS', 'TOL', 'PBI', 'CMH', 'OGD', 'MSP', 'ATL', 'DCA', 'BWI', 'STL', 'ORD', 'IAH', 'MLI', 'IDA', 'OAK', 'AUS', 'MFE', 'SPI', 'USA', 'DSM', 'BOI', 'BIS', 'GTF', 'PIA', 'FAR', 'EWR', 'SCK', 'GJT', 'BIL', 'MFR', 'CVG', 'TUS', 'CSG', 'RDM', 'HOU', 'GFK', 'CID']\n",
            "Number of rows with missing coordinates: 17348\n",
            "Number of rows after removal: 2982652\n",
            "Number of rows after removal: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format departure and arrival times to ensure they are in 'HH:MM' format\n",
        "df[\"CRS_DEP_TIME\"] = df[\"CRS_DEP_TIME\"].apply(lambda x: f\"{str(int(x)).zfill(4)[:2]}:{str(int(x)).zfill(4)[2:]}\")\n",
        "df[\"CRS_ARR_TIME\"] = df[\"CRS_ARR_TIME\"].apply(lambda x: f\"{str(int(x)).zfill(4)[:2]}:{str(int(x)).zfill(4)[2:]}\")\n",
        "\n",
        "# Verify that times are properly formatted as 'HH:MM'\n",
        "print(df[[\"CRS_DEP_TIME\", \"CRS_ARR_TIME\"]].head())"
      ],
      "metadata": {
        "id": "BjYM6c4c1_xL",
        "outputId": "cd9bca3f-5ce4-4d72-9334-e8d9146ac6fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  CRS_DEP_TIME CRS_ARR_TIME\n",
            "0        11:55        15:01\n",
            "1        21:20        23:15\n",
            "2        09:54        12:52\n",
            "3        16:09        18:29\n",
            "4        18:40        20:41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the Open-Meteo API client with cache and retry on error\n",
        "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
        "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
        "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
        "url = \"https://archive-api.open-meteo.com/v1/archive\""
      ],
      "metadata": {
        "id": "7MGV7mZmKd4K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_progress(data, filename):\n",
        "    with open(filename, \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "def load_progress(filename):\n",
        "    try:\n",
        "        with open(filename, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return []"
      ],
      "metadata": {
        "id": "6snwnaayZrsd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weather_data(date, time, latitude, longitude):\n",
        "\n",
        "  flight_datetime = datetime.strptime(f\"{date} {time}\", \"%Y-%m-%d %H:%M\")\n",
        "  start_date = flight_datetime.strftime(\"%Y-%m-%d\")\n",
        "  end_date = (flight_datetime + timedelta(hours=1)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "  params = {\n",
        "    \"latitude\": latitude,\n",
        "    \"longitude\": longitude,\n",
        "    \"start_date\": date,\n",
        "    \"end_date\": date,\n",
        "    \"hourly\": [\n",
        "        \"temperature_2m\",\n",
        "        \"precipitation\",\n",
        "        \"rain\",\n",
        "        \"snowfall\",\n",
        "        \"weather_code\",\n",
        "        \"windspeed_10m\",\n",
        "        \"windspeed_100m\",\n",
        "        \"winddirection_10m\",\n",
        "        \"winddirection_100m\",\n",
        "        \"windgusts_10m\",\n",
        "    ],\n",
        "    \"timezone\": \"auto\"\n",
        "  }\n",
        "\n",
        "  responses = openmeteo.weather_api(url, params=params)\n",
        "\n",
        "  if responses and isinstance(responses, list):\n",
        "    response = responses[0]\n",
        "    hourly_data = response.Hourly() if response else None\n",
        "  else:\n",
        "    hourly_data = None\n",
        "\n",
        "  if hourly_data:\n",
        "    hourly_variables = list(map(lambda i: hourly_data.Variables(i), range(0, hourly_data.VariablesLength())))\n",
        "\n",
        "    weather_data = {}\n",
        "\n",
        "    try:\n",
        "        weather_data[\"temperature_2m\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.temperature and x.Altitude() == 2, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "        weather_data[\"precipitation\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.precipitation, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "        weather_data[\"rain\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.rain, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "        weather_data[\"snowfall\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.snowfall, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "        weather_data[\"windspeed_10m\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.wind_speed and x.Altitude() == 10, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "        weather_data[\"windspeed_100m\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.wind_speed and x.Altitude() == 100, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "        weather_data[\"winddirection_10m\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.wind_direction and x.Altitude() == 10, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "        weather_data[\"winddirection_100m\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.wind_direction and x.Altitude() == 100, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "        weather_data[\"windgusts_10m\"] = next(\n",
        "            filter(lambda x: x.Variable() == Variable.wind_gusts and x.Altitude() == 10, hourly_variables)\n",
        "        ).ValuesAsNumpy()\n",
        "    except StopIteration:\n",
        "        print(\"One or more weather variables were not found in the response.\")\n",
        "        return None\n",
        "\n",
        "    return weather_data\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "4dKGrj2bMgjl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "origin_weather_data = load_progress(\"origin_weather.pkl\")\n",
        "destination_weather_data = load_progress(\"destination_weather.pkl\")\n",
        "\n",
        "# Fetch weather data\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Fetching weather data\"):\n",
        "        if index < len(origin_weather_data):\n",
        "            if index % 200 == 0:\n",
        "                print(\"still works\")\n",
        "            continue  # Skip already processed rows\n",
        "\n",
        "        # Fetch origin weather\n",
        "        origin_weather = get_weather_data(row[\"FL_DATE\"], row[\"CRS_DEP_TIME\"], row[\"ORIGIN_LAT\"], row[\"ORIGIN_LONG\"])\n",
        "        origin_weather_data.append(origin_weather)\n",
        "        save_progress(origin_weather_data, \"origin_weather.pkl\")\n",
        "\n",
        "        # Fetch destination weather\n",
        "        destination_weather = get_weather_data(row[\"FL_DATE\"], row[\"CRS_ARR_TIME\"], row[\"DEST_LAT\"], row[\"DEST_LONG\"])\n",
        "        destination_weather_data.append(destination_weather)\n",
        "        save_progress(destination_weather_data, \"destination_weather.pkl\")\n",
        "\n",
        "# Create DataFrames from weather data\n",
        "origin_weather_df = pd.DataFrame(origin_weather_data).add_prefix('origin_')\n",
        "destination_weather_df = pd.DataFrame(destination_weather_data).add_prefix('destination_')\n",
        "\n",
        "# Combine with the main DataFrame\n",
        "df = pd.concat([df, origin_weather_df, destination_weather_df], axis=1)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "tl8tlDLXRIeN",
        "outputId": "775b0629-ddae-45f9-fcb5-30843664484a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching weather data:  19%|█▉        | 1888/10000 [00:00<00:00, 18874.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFetching weather data:  38%|███▊      | 3776/10000 [00:00<00:00, 17532.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "still works\n",
            "still works\n",
            "still works\n",
            "still works\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFetching weather data:  45%|████▌     | 4501/10000 [00:01<00:01, 4066.33it/s] \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OpenMeteoRequestsError",
          "evalue": "{'error': True, 'reason': 'Hourly API request limit exceeded. Please try again in the next hour.'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenMeteoRequestsError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-de2922d51e1e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Fetch origin weather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0morigin_weather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_weather_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FL_DATE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CRS_DEP_TIME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ORIGIN_LAT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ORIGIN_LONG\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0morigin_weather_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_weather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msave_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_weather_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"origin_weather.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e21e79785668>\u001b[0m in \u001b[0;36mget_weather_data\u001b[0;34m(date, time, latitude, longitude)\u001b[0m\n\u001b[1;32m     25\u001b[0m   }\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenmeteo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweather_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresponses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openmeteo_requests/Client.py\u001b[0m in \u001b[0;36mweather_api\u001b[0;34m(self, url, params, method, verify)\u001b[0m\n\u001b[1;32m     52\u001b[0m     ) -> list[WeatherApiResponse]:\n\u001b[1;32m     53\u001b[0m         \u001b[0;34m\"\"\"Get and decode as weather api\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeatherApiResponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openmeteo_requests/Client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, cls, url, params, method, verify)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m429\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mresponse_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOpenMeteoRequestsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenMeteoRequestsError\u001b[0m: {'error': True, 'reason': 'Hourly API request limit exceeded. Please try again in the next hour.'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the features that we want\n",
        "\n",
        "required_columns = [\n",
        "    'FL_DATE',\n",
        "    'AIRLINE',\n",
        "    'FL_NUMBER',\n",
        "    'ORIGIN',\n",
        "    'DEST',\n",
        "    'CRS_DEP_TIME',\n",
        "    'CRS_ARR_TIME',\n",
        "    'CRS_ELAPSED_TIME',\n",
        "    'DISTANCE',\n",
        "    'DEP_DELAY',\n",
        "    'ARR_DELAY',\n",
        "    'DELAY_DUE_WEATHER'\n",
        "]\n",
        "\n",
        "weather_columns = [col for col in df.columns if col.startswith('origin_') or col.startswith('destination_')]\n",
        "\n",
        "final_columns = required_columns + weather_columns\n",
        "\n",
        "df = df[final_columns]\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "4y279QsNaPyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the cleaned data to a new csv\n",
        "\n",
        "df.to_csv('flight_data_with_weather.csv', index=False)\n",
        "\n",
        "print(\"Data saved to 'flight_data_with_weather.csv'\")"
      ],
      "metadata": {
        "id": "byuhgF6i22Gn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}